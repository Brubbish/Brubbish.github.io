<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/unnamed.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/photo.gif">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="eaKNHevzJD712W6CICpiQ4_TgpzOgFr3dBKOwg7Hqs4">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"brubbish.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false,"search":null,"path":"search.xml","field":"post","format":"html","limit":10000},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="就此开一篇单独记录 py 爬虫的学习以及实操中遇到的问题(可能吧)（分割线用（***或—-））">
<meta property="og:type" content="article">
<meta property="og:title" content="python 爬虫学习">
<meta property="og:url" content="https://brubbish.github.io/710f8e5f.html">
<meta property="og:site_name" content="Brubbish&#39;s">
<meta property="og:description" content="就此开一篇单独记录 py 爬虫的学习以及实操中遇到的问题(可能吧)（分割线用（***或—-））">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/17/8tyB5j.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/17/8tysGn.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/17/8tyy2q.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/17/8ty6x0.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/19/8y3yQ0.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/19/8yjZ5R.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/19/8yjEVJ.md.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/21/8fFk0H.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/21/8fFPXD.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/21/8fFFne.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/03/26/GSHMGD.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/02/GGx6qs.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/02/GGxyrj.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/05/GBh3Pf.png">
<meta property="article:published_time" content="2020-03-16T15:58:00.000Z">
<meta property="article:modified_time" content="2020-07-05T13:36:52.000Z">
<meta property="article:author" content="Bruce">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/03/17/8tyB5j.md.png">

<link rel="canonical" href="https://brubbish.github.io/710f8e5f.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>python 爬虫学习 | Brubbish's</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-153514659-2"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-153514659-2');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Brubbish's" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Brubbish's</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://brubbish.github.io/710f8e5f.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bruce">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Brubbish's">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          python 爬虫学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-16 23:58:00" itemprop="dateCreated datePublished" datetime="2020-03-16T23:58:00+08:00">2020-03-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-05 21:36:52" itemprop="dateModified" datetime="2020-07-05T21:36:52+08:00">2020-07-05</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>就此开一篇单独记录 py 爬虫的学习<u>以及实操中遇到的问题</u>(可能吧)<br>（分割线用（***或—-））</p>
<h2 id=""><a href="#" class="headerlink" title=""></a><a id="more"></a></h2><h1 id="爬虫入门"><a href="#爬虫入门" class="headerlink" title="爬虫入门"></a>爬虫入门</h1><p>以下为 mooc 上 BIT 嵩天老师课程<a href="https://www.icourse163.org/learn/BIT-1001870001?tid=1206951268#/learn/announce" target="_blank" rel="noopener">Python 网络爬虫与信息提取</a>的学习</p>
<h2 id="requests-库"><a href="#requests-库" class="headerlink" title="requests 库"></a>requests 库</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>管理员打开 cmd，安装 requests 库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/17/8tyB5j.md.png" alt="以此检测安装成功"></p>
<h4 id="tip：-pip-下载超时（timeout）"><a href="#tip：-pip-下载超时（timeout）" class="headerlink" title="tip： pip 下载超时（timeout）"></a>tip： pip 下载超时（timeout）</h4><p>cmd 输入指令：</p>
<ol>
<li>pip —default-timeout=100 install -U pip</li>
</ol>
<p>或</p>
<ol>
<li>pip install pip -U</li>
</ol>
<p>pip config set global.index-url <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a><br> （升级 pip 后更换为的清华镜像）</p>
<h3 id="r-request-get-url"><a href="#r-request-get-url" class="headerlink" title="r=request.get(url)"></a>r=request.get(url)</h3><p>构造一个向服务器请求资源的 request 对象，返回一个包含服务器资源的 response 对象<br>response 对象包含了服务器返回的所有信息</p>
<p><img src="https://s1.ax1x.com/2020/03/17/8tysGn.md.png" alt="8tysGn.md.png"></p>
<p>r.apparent_encoding: 根据网页内容分析出的编码方式<br>r.encoding: 如果 header 中不存在 charset，则默认编码为 ISO-8859-1</p>
<h3 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h3><p><img src="https://s1.ax1x.com/2020/03/17/8tyy2q.md.png" alt="8tyy2q.md.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requsets</span><br><span class="line"><span class="comment">#----</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url,timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()    <span class="comment"># 判断状态  如果不是200，则引发HTTPError异常</span></span><br><span class="line">        r.encoding=r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"><span class="comment">#----</span></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    url=<span class="string">"http://www.baidu.com"</span></span><br><span class="line">    print(<span class="string">"getHTMLText(url))</span></span><br></pre></td></tr></table></figure>
<p>try：python 捕捉异常语句，详见：<a href="https://www.runoob.com/python/python-exceptions.html" target="_blank" rel="noopener">https://www.runoob.com/python/python-exceptions.html</a></p>
<h3 id="requests-库主要方法"><a href="#requests-库主要方法" class="headerlink" title="requests 库主要方法"></a>requests 库主要方法</h3><p><img src="https://s1.ax1x.com/2020/03/17/8ty6x0.md.png" alt="8ty6x0.md.png"></p>
<p>requests.request(method, url, <strong>kwargs)<br>requests.get(url, params=None, </strong>kwargs)<br>requests.head(url, <strong>kwargs)<br>requests.post(url, data=None, json=None, </strong>kwargs)<br>requests.put(url, data=None, <strong>kwargs)<br>requests.patch(url, data=None, </strong>kwargs)<br>requests.delete(url, **kwargs)</p>
<h4 id="kwargs"><a href="#kwargs" class="headerlink" title="**kwargs:"></a>**kwargs:</h4><ol>
<li>params：字典或字节序列，作为参数添加到 url 中</li>
<li>data：字典、字节序列或文件对象，作为 request 的内容</li>
<li>json：json 格式的数据，作为 request 的内容</li>
<li>headers：定制 header</li>
<li>cookies</li>
<li>auth</li>
<li>files：传输文件</li>
<li>timeout：设定超时时间，单位为秒</li>
<li>proxies：设置代理服务器</li>
<li>allow_redirects</li>
<li>stream</li>
<li>verify</li>
<li>cert</li>
</ol>
<h3 id="爬虫尺寸"><a href="#爬虫尺寸" class="headerlink" title="爬虫尺寸"></a>爬虫尺寸</h3><p>小规模：爬取网页。数据量小，速度不敏感。使用 requests 库<br>中规模：爬取网站。数据量大，速度敏感。使用 scrapy 库<br>大规模：爬取全网。（搜索引擎）</p>
<h3 id="限制爬虫"><a href="#限制爬虫" class="headerlink" title="限制爬虫"></a>限制爬虫</h3><ol>
<li>来源审查：判断 user-agent</li>
<li>robots 协议</li>
</ol>
<h3 id="robots-协议"><a href="#robots-协议" class="headerlink" title="robots 协议"></a>robots 协议</h3><p>Robots Exclusion Standard<br>网络爬虫先识别 robots.txt 再进行爬取<br>robots 协议时建议而非约束性，不遵守的话存在法律风险（类人行为可不参考 robots 协议）</p>
<h3 id="拒绝被爬：尝试修改-user-agent"><a href="#拒绝被爬：尝试修改-user-agent" class="headerlink" title="拒绝被爬：尝试修改 user-agent"></a>拒绝被爬：尝试修改 user-agent</h3><p><img src="https://s1.ax1x.com/2020/03/19/8y3yQ0.md.png" alt="主要为黄色荧光部分"></p>
<h3 id="搜索引擎关键词提交"><a href="#搜索引擎关键词提交" class="headerlink" title="搜索引擎关键词提交"></a>搜索引擎关键词提交</h3><p>百度：<a href="https://www.baidu.com/s?wd=" target="_blank" rel="noopener">https://www.baidu.com/s?wd=</a><u>关键词</u></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keyword=<span class="string">"xxxx"</span></span><br><span class="line"></span><br><span class="line">kv=&#123;<span class="string">'wd'</span>:keyword&#125;</span><br><span class="line"></span><br><span class="line">r=requests.get(<span class="string">"https://www.baidu.com/s"</span>,params=kv)</span><br></pre></td></tr></table></figure>
<h3 id="图片的爬取和存储"><a href="#图片的爬取和存储" class="headerlink" title="图片的爬取和存储"></a>图片的爬取和存储</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">url=<span class="string">"....../...jpg"</span></span><br><span class="line">root=<span class="string">"D://pics//"</span></span><br><span class="line">path=root+url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]    <span class="comment">#需要import os</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        r=requests.get(url)</span><br><span class="line">        <span class="comment">#保存↓</span></span><br><span class="line">        <span class="keyword">with</span> open(path,<span class="string">'wb'</span>)<span class="keyword">as</span> f:</span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">            print(<span class="string">"成功“)</span></span><br><span class="line"><span class="string">    else:</span></span><br><span class="line"><span class="string">        print("</span>文件已存在<span class="string">")</span></span><br><span class="line"><span class="string">except:</span></span><br><span class="line"><span class="string">    print("</span>失败<span class="string">")</span></span><br></pre></td></tr></table></figure>
<h2 id="BeautifulSoup-库"><a href="#BeautifulSoup-库" class="headerlink" title="BeautifulSoup 库"></a>BeautifulSoup 库</h2><p>BeautifulSoup 库是一个解析、遍历、维护标签树的功能库</p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>cmd 下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>
<p>使用：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">或</span><br><span class="line"><span class="keyword">import</span> bs4</span><br></pre></td></tr></table></figure>
<p>作用：html 文档 ↔ 标签树 ↔beautifulsoup 类</p>
<h3 id="BeautifulSoup-基本元素"><a href="#BeautifulSoup-基本元素" class="headerlink" title="BeautifulSoup 基本元素"></a>BeautifulSoup 基本元素</h3><p><img src="https://s1.ax1x.com/2020/03/19/8yjZ5R.md.png" alt="8yjZ5R.md.png"></p>
<p><img src="https://s1.ax1x.com/2020/03/19/8yjEVJ.md.png" alt="8yjEVJ.md.png"></p>
<p>例：<br>打印标签</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">r=requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line">demo=r.text</span><br><span class="line">soup=BeautifulSoup(demo,<span class="string">"html.parser"</span>)  <span class="comment">#parser:html解析器</span></span><br><span class="line">soup.title  <span class="comment">#打印title标签</span></span><br><span class="line">soup.a.attrs[<span class="string">"href"</span>]   <span class="comment">#打印标签的链接</span></span><br></pre></td></tr></table></figure>
<h3 id="html-内容遍历"><a href="#html-内容遍历" class="headerlink" title="html 内容遍历"></a>html 内容遍历</h3><p>html—树形结构<br>遍历：下行遍历、上行遍历、平行遍历</p>
<h4 id="下行遍历："><a href="#下行遍历：" class="headerlink" title="下行遍历："></a>下行遍历：</h4><p><img src="https://s1.ax1x.com/2020/03/21/8fFk0H.png" alt=" "></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(child) <span class="keyword">in</span> soup.body.children:</span><br><span class="line">    print(child)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">获得子节点的数量：</span><br><span class="line">len(soup.body.contents)</span><br><span class="line"></span><br><span class="line">获得其中某个的内容：</span><br><span class="line">soup.body.contents[<span class="number">1</span>]   <span class="comment">#获得第二个</span></span><br></pre></td></tr></table></figure>
<p>ps:’儿子节点’这种叫法听起来真是贼奇怪</p>
<h4 id="上行遍历："><a href="#上行遍历：" class="headerlink" title="上行遍历："></a>上行遍历：</h4><p><img src="https://s1.ax1x.com/2020/03/21/8fFPXD.png" alt=" "></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">查看父标签:</span><br><span class="line">soup.title.parent</span><br><span class="line">最高级标签（&lt;html&gt;他爸是他自己（.....)</span><br><span class="line"></span><br><span class="line">完整遍历：</span><br><span class="line">soup=BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.a.parents:</span><br><span class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        print(parent)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(parent)</span><br></pre></td></tr></table></figure>
<h4 id="平行遍历："><a href="#平行遍历：" class="headerlink" title="平行遍历："></a>平行遍历：</h4><p>发生在同一个父节点下的各个节点间<br>平行遍历获得的下一个结点不一定是标签类型</p>
<p><img src="https://s1.ax1x.com/2020/03/21/8fFFne.png" alt=" "></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">查看下一个平行标签:</span><br><span class="line">soup.a.next_sibling</span><br><span class="line">查看前一个平行标签:</span><br><span class="line">soup.a.previous_sibling</span><br><span class="line"></span><br><span class="line">完整：</span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next（或前序结点previous）_siblings:</span><br><span class="line">    print(sibling)</span><br></pre></td></tr></table></figure>
<h3 id="Prettify"><a href="#Prettify" class="headerlink" title="Prettify"></a>Prettify</h3><p>作用：在每个标签后添加换行符，print 的时候易于阅读<br>使用方法：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(soup.prettify())</span><br><span class="line"></span><br><span class="line">print(soup.a.prettify())    <span class="comment">#单独对某个标签进行处理</span></span><br></pre></td></tr></table></figure>
<p>&emsp;</p>
<p>以上为 2020.3.16-2020.3.21</p>
<hr>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>regular expression (RE)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>操作符</th>
<th>说明</th>
<th>实例                              </th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>任何单个字符</td>
</tr>
<tr>
<td>[ ]</td>
<td>字符集</td>
<td>[abc]:a、b、c; [a-z]:a~z 单个字符 </td>
</tr>
<tr>
<td><sup><a href="#fn_ " id="reffn_ "> </a></sup></td>
<td>非字符集</td>
<td><sup><a href="#fn_abc" id="reffn_abc">abc</a></sup>: 非 a、b、c 的单个字符     </td>
</tr>
<tr>
<td>*</td>
<td>前一个字符 0 次或无限次扩展</td>
<td>abc *：ab、abc、abcc… ..       </td>
</tr>
<tr>
<td>+</td>
<td>前一个字符 1 次或无限次扩展</td>
<td>abc *：abc、abcc… ..          </td>
</tr>
<tr>
<td>?</td>
<td>前一个字符 0 次或 1 次扩展</td>
<td>abc *：abc、abcc… ..           </td>
</tr>
<tr>
<td>\</td>
<td></td>
<td>左右表达式任意一个： abc\ def :abc 或 def </td>
</tr>
<tr>
<td>{num}</td>
<td>扩展前一个字符 m 次</td>
<td>ab{2}c：abbc                     </td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串开头</td>
<td>^abc:abc 在字符串的开头         </td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串结尾</td>
<td>$abc:abc 在字符串的结尾     </td>
</tr>
<tr>
<td>( )</td>
<td>分组标记，内部使用\</td>
<td>操作符 (abc):abc; (abc</td>
<td>def):abc 或 def </td>
</tr>
<tr>
<td>\d</td>
<td>等价于 0~9</td>
</tr>
<tr>
<td>\w</td>
<td>等价于 A ~ Z, a ~ z, 0 ~ 9, _</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.runoob.com/regexp/regexp-tutorial.html" target="_blank" rel="noopener">https://www.runoob.com/regexp/regexp-tutorial.html</a></p>
<h2 id="Re-库"><a href="#Re-库" class="headerlink" title="Re 库"></a>Re 库</h2><h3 id="调用方法"><a href="#调用方法" class="headerlink" title="调用方法"></a>调用方法</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure>
<h3 id="表达式的表达类型"><a href="#表达式的表达类型" class="headerlink" title="表达式的表达类型"></a>表达式的表达类型</h3><p>raw string：不包含转义符(\)的字符串<br>string 类型(将’\’理解为转义符)<br>raw string 如：r’[1-9]\d{5}’、r’\d{3}-\d{8}\d{4}-\d{7}’<br>string 如：[1-9]\\\d{5}’\\\d{3}-\\\d{8}\\\d{4}-\\\d{7}’</p>
<h3 id="主要功能函数"><a href="#主要功能函数" class="headerlink" title="主要功能函数"></a>主要功能函数</h3><p><img src="https://s1.ax1x.com/2020/03/26/GSHMGD.png" alt=" "></p>
<ol>
<li>re.search(pattern,string,flags=0)</li>
<li>re.match(pattern,string,flags=0)</li>
<li>re.findall(pattern,string,flags=0)</li>
<li>re.finditer(pattern,stirng,flags=0)</li>
</ol>
<p>pattern: 正则表达式的字符串或原生字符串表示<br>string：待匹配字符串</p>
<p>flags：正则表达式使用时的一些控制标记，包括：<br>re. I:ignorecase, 忽略大小写<br>re. M:multiline, 使用’^’时将每行都当作匹配开始<br>re. S:dotall, 让’.’匹配所有字符，包括换行符</p>
<ol>
<li>re.search(pattern,string,maxsplit=0,flags=0)</li>
</ol>
<p>maxsplit: 最大分割数，限制分割的数量为 n，将剩下的所有部分输出为第 n+1 个</p>
<ol>
<li>re.sub(pattern,repl,string,count=0,flags=0)</li>
</ol>
<p>repl: 替换的字符串<br>count：替换的最大次数<br>&emsp;</p>
<p>以上为2020.03.22-2020.03.28</p>
<hr>
<h3 id="RE库的match对象"><a href="#RE库的match对象" class="headerlink" title="RE库的match对象"></a>RE库的match对象</h3><p>用 type(match)检查 match 的类型</p>
<p><img src="https://s1.ax1x.com/2020/04/02/GGx6qs.png" alt=" "><br><img src="https://s1.ax1x.com/2020/04/02/GGxyrj.png" alt=" "></p>
<h3 id="贪婪匹配和最小匹配"><a href="#贪婪匹配和最小匹配" class="headerlink" title="贪婪匹配和最小匹配"></a>贪婪匹配和最小匹配</h3><p>re库默认采用贪婪匹配，即输出匹配最长的子串</p>
<h2 id="Scrapy库"><a href="#Scrapy库" class="headerlink" title="Scrapy库"></a>Scrapy库</h2><h3 id="scrapy爬虫框架安装"><a href="#scrapy爬虫框架安装" class="headerlink" title="scrapy爬虫框架安装"></a>scrapy爬虫框架安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br><span class="line">scrapy -h    # 测试安装成功</span><br></pre></td></tr></table></figure>
<h3 id="scrapy-爬虫框架结构"><a href="#scrapy-爬虫框架结构" class="headerlink" title="scrapy 爬虫框架结构"></a>scrapy 爬虫框架结构</h3><p>5个主体+2个中间件<br>3个主体（engine+downloader+scheduler）为已有实现<br>2个主体（item pipelines+spiders）为用户配置：<br>item pipelines对获得信息进行处理<br>spiders提供url和解析网页的内容  </p>
<p>**以下3个不需要用户配置<br>engine控制所有模块之间的数据流，根据条件触发事件<br>downloader根据请求下载<br>scheduler对所有爬取进行调度<br>在以上三个中有一个中间件：downloader middleware   </p>
<h3 id="scrapy库爬虫常用命令"><a href="#scrapy库爬虫常用命令" class="headerlink" title="scrapy库爬虫常用命令"></a>scrapy库爬虫常用命令</h3><p>格式：scrapy<command>[options][args]<br>一个工程是最大的单元（大的scrapy框架），其中有多个spider<br><img src="https://s1.ax1x.com/2020/04/05/GBh3Pf.png" alt=" "></p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>….</p>
<h2 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h2><h3 id="中国大学排名爬取"><a href="#中国大学排名爬取" class="headerlink" title="中国大学排名爬取"></a>中国大学排名爬取</h3><p>数据来源：<a href="http://www.zuihaodaxue.com/zuihaodaxuepaiming2019.html" target="_blank" rel="noopener">软科中国最好大学排名2019</a>   </p>
<ol>
<li>获取网页内容：gethtmltext()  </li>
<li>提取信息到合适的数据结构：fillunivlist()  </li>
<li>输出结果：printunivlist()</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gethtmltext</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url,timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding=r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">" "</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillunivlist</span><span class="params">(ulist,html)</span>:</span></span><br><span class="line">    soup=BeautifulSoup(html,<span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr,bs4.element.Tag):</span><br><span class="line">            tds=tr(<span class="string">'td'</span>)</span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string,tds[<span class="number">1</span>].string,tds[<span class="number">3</span>].string])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printunivlist</span><span class="params">(ulist,num)</span>:</span></span><br><span class="line">    print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(<span class="string">"排名"</span>,<span class="string">"学校名称"</span>,<span class="string">"总分"</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u=ulist[i]</span><br><span class="line">        print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>]))</span><br><span class="line">        </span><br><span class="line">    print(<span class="string">"suc"</span>+str(num))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo=[]<span class="comment"># 存放大学信息</span></span><br><span class="line">    url=<span class="string">"http://www.zuihaodaxue.com/zuihaodaxuepaiming2019.html"</span></span><br><span class="line">    html=gethtmltext(url)</span><br><span class="line">    fillunivlist(uinfo,html)</span><br><span class="line">    printunivlist(uinfo,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/232092d7.html" rel="prev" title="2020.03.08-2020.03.15">
      <i class="fa fa-chevron-left"></i> 2020.03.08-2020.03.15
    </a></div>
      <div class="post-nav-item">
    <a href="/dcd92ddb.html" rel="next" title="2020.03.16-2020.03.22">
      2020.03.16-2020.03.22 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#"><span class="nav-number">1.</span> <span class="nav-text"></span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#爬虫入门"><span class="nav-number"></span> <span class="nav-text">爬虫入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#requests-库"><span class="nav-number">1.</span> <span class="nav-text">requests 库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装"><span class="nav-number">1.1.</span> <span class="nav-text">安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#tip：-pip-下载超时（timeout）"><span class="nav-number">1.1.1.</span> <span class="nav-text">tip： pip 下载超时（timeout）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#r-request-get-url"><span class="nav-number">1.2.</span> <span class="nav-text">r&#x3D;request.get(url)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#爬取网页的通用代码框架"><span class="nav-number">1.3.</span> <span class="nav-text">爬取网页的通用代码框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#requests-库主要方法"><span class="nav-number">1.4.</span> <span class="nav-text">requests 库主要方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kwargs"><span class="nav-number">1.4.1.</span> <span class="nav-text">**kwargs:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#爬虫尺寸"><span class="nav-number">1.5.</span> <span class="nav-text">爬虫尺寸</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#限制爬虫"><span class="nav-number">1.6.</span> <span class="nav-text">限制爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#robots-协议"><span class="nav-number">1.7.</span> <span class="nav-text">robots 协议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拒绝被爬：尝试修改-user-agent"><span class="nav-number">1.8.</span> <span class="nav-text">拒绝被爬：尝试修改 user-agent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#搜索引擎关键词提交"><span class="nav-number">1.9.</span> <span class="nav-text">搜索引擎关键词提交</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图片的爬取和存储"><span class="nav-number">1.10.</span> <span class="nav-text">图片的爬取和存储</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BeautifulSoup-库"><span class="nav-number">2.</span> <span class="nav-text">BeautifulSoup 库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装-1"><span class="nav-number">2.1.</span> <span class="nav-text">安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BeautifulSoup-基本元素"><span class="nav-number">2.2.</span> <span class="nav-text">BeautifulSoup 基本元素</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#html-内容遍历"><span class="nav-number">2.3.</span> <span class="nav-text">html 内容遍历</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#下行遍历："><span class="nav-number">2.3.1.</span> <span class="nav-text">下行遍历：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#上行遍历："><span class="nav-number">2.3.2.</span> <span class="nav-text">上行遍历：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#平行遍历："><span class="nav-number">2.3.3.</span> <span class="nav-text">平行遍历：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prettify"><span class="nav-number">2.4.</span> <span class="nav-text">Prettify</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则表达式"><span class="nav-number">3.</span> <span class="nav-text">正则表达式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Re-库"><span class="nav-number">4.</span> <span class="nav-text">Re 库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#调用方法"><span class="nav-number">4.1.</span> <span class="nav-text">调用方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#表达式的表达类型"><span class="nav-number">4.2.</span> <span class="nav-text">表达式的表达类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主要功能函数"><span class="nav-number">4.3.</span> <span class="nav-text">主要功能函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RE库的match对象"><span class="nav-number">4.4.</span> <span class="nav-text">RE库的match对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贪婪匹配和最小匹配"><span class="nav-number">4.5.</span> <span class="nav-text">贪婪匹配和最小匹配</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy库"><span class="nav-number">5.</span> <span class="nav-text">Scrapy库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#scrapy爬虫框架安装"><span class="nav-number">5.1.</span> <span class="nav-text">scrapy爬虫框架安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#scrapy-爬虫框架结构"><span class="nav-number">5.2.</span> <span class="nav-text">scrapy 爬虫框架结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#scrapy库爬虫常用命令"><span class="nav-number">5.3.</span> <span class="nav-text">scrapy库爬虫常用命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实例"><span class="nav-number">5.4.</span> <span class="nav-text">实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实例-1"><span class="nav-number">6.</span> <span class="nav-text">实例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#中国大学排名爬取"><span class="nav-number">6.1.</span> <span class="nav-text">中国大学排名爬取</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Bruce</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bruce</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
